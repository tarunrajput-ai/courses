# Keras Layers Complete Guide - Python Script for Google Colab
# Save this as a .py file or copy directly into Colab cells

"""
KERAS MODEL LAYERS - COMPLETE GUIDE WITH EXAMPLES
==================================================
Run this in Google Colab for GPU acceleration!
"""

import time

# ============================================================================
# SETUP AND IMPORTS
# ============================================================================
print("Installing and importing libraries...")
start_time = time.time()

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras import layers, models
from keras.datasets import mnist, fashion_mnist

setup_time = time.time() - start_time

print(f"‚úÖ TensorFlow version: {tf.__version__}")
print(f"‚úÖ Keras version: {keras.__version__}")
print(f"‚úÖ GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}")
print(f"‚è±Ô∏è  Setup time: {setup_time:.2f} seconds")

# ============================================================================
# 1. DENSE LAYERS (FULLY CONNECTED)
# ============================================================================
print("\n" + "="*80)
print("1. DENSE LAYERS (FULLY CONNECTED)")
print("="*80)

model_dense = models.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

print("\nüìä Dense Layer Architecture:")
model_dense.summary()
print("\nFlow: Input(784) -> Dense(128) -> Dense(64) -> Dense(10)")

# ============================================================================
# 2. CONVOLUTIONAL LAYERS (Conv2D)
# ============================================================================
print("\n" + "="*80)
print("2. CONVOLUTIONAL LAYERS (Conv2D)")
print("="*80)

model_cnn = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

print("\nüîç CNN Architecture:")
model_cnn.summary()
print("\nüí° Conv2D detects patterns like edges, shapes, and textures")

# ============================================================================
# 3. POOLING LAYERS
# ============================================================================
print("\n" + "="*80)
print("3. POOLING LAYERS")
print("="*80)

sample_input = np.random.rand(1, 8, 8, 1)
pooling_layer = layers.MaxPooling2D((2, 2))
pooled_output = pooling_layer(sample_input)

print(f"\nInput shape: {sample_input.shape}")
print(f"After MaxPooling(2,2): {pooled_output.shape}")
print(f"Size reduction: 75%")
print("\n‚úÖ Benefits: Reduces computation, provides translation invariance")

# ============================================================================
# 4. DROPOUT LAYERS
# ============================================================================
print("\n" + "="*80)
print("4. DROPOUT LAYERS")
print("="*80)

model_dropout = models.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10, activation='softmax')
])

print("\nüíä Model with Dropout:")
model_dropout.summary()
print("\nüí° Prevents overfitting by randomly dropping neurons during training")

# ============================================================================
# 5. BATCH NORMALIZATION
# ============================================================================
print("\n" + "="*80)
print("5. BATCH NORMALIZATION")
print("="*80)

model_bn = models.Sequential([
    layers.Dense(128, input_shape=(784,)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.Dense(64),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.Dense(10, activation='softmax')
])

print("\n‚ö° Model with BatchNormalization:")
model_bn.summary()
print("\n‚úÖ Benefits: Faster training, higher learning rates possible")

# ============================================================================
# 6. RECURRENT LAYERS (LSTM)
# ============================================================================
print("\n" + "="*80)
print("6. RECURRENT LAYERS (LSTM)")
print("="*80)

model_lstm = models.Sequential([
    layers.LSTM(128, return_sequences=True, input_shape=(100, 10)),
    layers.LSTM(64),
    layers.Dense(10, activation='softmax')
])

print("\nüîÑ LSTM Architecture:")
model_lstm.summary()
print("\nüìù Use cases: Time series, NLP, speech recognition, video analysis")

# ============================================================================
# 7. EMBEDDING LAYERS
# ============================================================================
print("\n" + "="*80)
print("7. EMBEDDING LAYERS")
print("="*80)

model_embed = models.Sequential([
    layers.Embedding(input_dim=10000, output_dim=128, input_length=100),
    layers.LSTM(64),
    layers.Dense(1, activation='sigmoid')
])

print("\nüìñ Model with Embedding:")
model_embed.summary()
print("\nüí° Converts words (integers) to dense vectors for NLP tasks")

# ============================================================================
# 8. FLATTEN LAYER
# ============================================================================
print("\n" + "="*80)
print("8. FLATTEN LAYER")
print("="*80)

sample_conv = np.random.rand(1, 7, 7, 64)
flatten_layer = layers.Flatten()
flattened = flatten_layer(sample_conv)

print(f"\nBefore Flatten: {sample_conv.shape}")
print(f"After Flatten: {flattened.shape}")
print(f"Calculation: 7 √ó 7 √ó 64 = {7*7*64}")
print("\n‚úÖ Use: Transition from Conv layers to Dense layers")

# ============================================================================
# 9. COMPLETE MNIST EXAMPLE
# ============================================================================
print("\n" + "="*80)
print("9. COMPLETE MNIST EXAMPLE - TRAINING A REAL MODEL!")
print("="*80)

# Load data
print("\nüì• Loading MNIST dataset...")
load_start = time.time()
(x_train, y_train), (x_test, y_test) = mnist.load_data()
load_time = time.time() - load_start

# Preprocess
print("üîÑ Preprocessing data...")
preprocess_start = time.time()
x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255
x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255
y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)
preprocess_time = time.time() - preprocess_start

print(f"‚úÖ Training data: {x_train.shape}")
print(f"‚úÖ Test data: {x_test.shape}")
print(f"‚è±Ô∏è  Data loading time: {load_time:.2f} seconds")
print(f"‚è±Ô∏è  Preprocessing time: {preprocess_time:.2f} seconds")

# Visualize samples
plt.figure(figsize=(10, 2))
for i in range(10):
    plt.subplot(1, 10, i+1)
    plt.imshow(x_train[i].reshape(28, 28), cmap='gray')
    plt.title(f"{np.argmax(y_train[i])}")
    plt.axis('off')
plt.suptitle('Sample MNIST Digits', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# Build model
print("\nüèóÔ∏è Building comprehensive model...")
build_start = time.time()

model_complete = models.Sequential([
    # Conv Block 1
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    
    # Conv Block 2
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    
    # Dense Block
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

build_time = time.time() - build_start

print("\nüìä Model Architecture:")
model_complete.summary()
print(f"‚è±Ô∏è  Model building time: {build_time:.3f} seconds")

# Compile
print("\n‚öôÔ∏è  Compiling model...")
compile_start = time.time()

model_complete.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

compile_time = time.time() - compile_start
print(f"‚úÖ Model compiled!")
print(f"‚è±Ô∏è  Compilation time: {compile_time:.3f} seconds")

# Train
print("\nüöÄ Training model (this may take a few minutes)...\n")
train_start = time.time()

history = model_complete.fit(
    x_train, y_train,
    batch_size=128,
    epochs=5,
    validation_split=0.1,
    verbose=1
)

train_time = time.time() - train_start

print(f"\n‚úÖ Training completed!")
print(f"‚è±Ô∏è  Total training time: {train_time:.2f} seconds ({train_time/60:.2f} minutes)")
print(f"‚è±Ô∏è  Average time per epoch: {train_time/5:.2f} seconds")

# Calculate training speed
total_samples = len(x_train) * 5  # samples √ó epochs
samples_per_second = total_samples / train_time
print(f"üìä Training speed: {samples_per_second:.0f} samples/second")

# Evaluate
print("\nüîç Evaluating on test set...")
eval_start = time.time()
test_loss, test_acc = model_complete.evaluate(x_test, y_test, verbose=0)
eval_time = time.time() - eval_start

print(f"\nüìä FINAL RESULTS:")
print(f"‚úÖ Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")
print(f"‚úÖ Test Loss: {test_loss:.4f}")
print(f"‚è±Ô∏è  Evaluation time: {eval_time:.2f} seconds")
print(f"‚è±Ô∏è  Inference speed: {len(x_test)/eval_time:.0f} samples/second")

# Plot training history
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

ax1.plot(history.history['accuracy'], label='Training', linewidth=2)
ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)
ax1.set_xlabel('Epoch', fontsize=12)
ax1.set_ylabel('Accuracy', fontsize=12)
ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2.plot(history.history['loss'], label='Training', linewidth=2)
ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)
ax2.set_xlabel('Epoch', fontsize=12)
ax2.set_ylabel('Loss', fontsize=12)
ax2.set_title('Model Loss', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Predictions
print("\nüéØ Making predictions on test samples...")
pred_start = time.time()
predictions = model_complete.predict(x_test[:20], verbose=0)
pred_time = time.time() - pred_start

predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test[:20], axis=1)

print(f"‚è±Ô∏è  Prediction time for 20 samples: {pred_time:.4f} seconds")
print(f"‚è±Ô∏è  Average time per sample: {pred_time/20*1000:.2f} milliseconds")
print(f"üìä Throughput: {20/pred_time:.0f} samples/second")

# Single sample inference benchmark
print("\n‚ö° Single sample inference benchmark...")
single_sample = x_test[0:1]
single_times = []

# Warm up
_ = model_complete.predict(single_sample, verbose=0)

# Benchmark 100 runs
for _ in range(100):
    start = time.time()
    _ = model_complete.predict(single_sample, verbose=0)
    single_times.append(time.time() - start)

avg_single_time = np.mean(single_times) * 1000  # Convert to ms
std_single_time = np.std(single_times) * 1000

print(f"‚è±Ô∏è  Average single inference: {avg_single_time:.2f} ¬± {std_single_time:.2f} ms")
print(f"‚è±Ô∏è  Min: {np.min(single_times)*1000:.2f} ms, Max: {np.max(single_times)*1000:.2f} ms")

plt.figure(figsize=(15, 3))
for i in range(20):
    plt.subplot(2, 10, i+1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    color = 'green' if predicted_classes[i] == true_classes[i] else 'red'
    plt.title(f"P:{predicted_classes[i]}\nT:{true_classes[i]}", 
              fontsize=10, color=color)
    plt.axis('off')

plt.suptitle('Predictions vs True Labels (Green=Correct, Red=Wrong)', 
             fontsize=12, fontweight='bold')
plt.tight_layout()
plt.show()

# ============================================================================
# 10. LAYER VISUALIZATION
# ============================================================================
print("\n" + "="*80)
print("10. LAYER VISUALIZATION")
print("="*80)

# Simple approach: manually pass data through layers
print("\nüîç Visualizing how data transforms through layers...")
viz_start = time.time()

sample_image = x_test[0:1]
print(f"\nOriginal input shape: {sample_image.shape}")

# Get the layers from our trained model
conv_layer_1 = model_complete.layers[0]  # First Conv2D
batch_norm_1 = model_complete.layers[1]  # BatchNorm

# Manually pass data through layers
layer_start = time.time()
conv1_output = conv_layer_1(sample_image)
conv_time = time.time() - layer_start
print(f"After first Conv2D: {conv1_output.shape}")
print(f"  - Started with 1 channel, now have 32 feature maps")
print(f"  ‚è±Ô∏è  Conv2D inference: {conv_time*1000:.2f} ms")

# Apply batch normalization
bn_start = time.time()
bn1_output = batch_norm_1(conv1_output, training=False)
bn_time = time.time() - bn_start
print(f"After BatchNormalization: {bn1_output.shape}")
print(f"  - Shape unchanged, but values normalized")
print(f"  ‚è±Ô∏è  BatchNorm inference: {bn_time*1000:.2f} ms")

# Visualize the feature maps from first conv layer
print("\nüìä Visualizing first 10 (out of 32) feature maps...")

plt.figure(figsize=(15, 3))

# Original image
plt.subplot(1, 11, 1)
plt.imshow(sample_image[0, :, :, 0], cmap='gray')
plt.title('Original\nInput', fontsize=9, fontweight='bold')
plt.axis('off')

# Show first 10 feature maps
for i in range(10):
    plt.subplot(1, 11, i+2)
    feature_map = conv1_output[0, :, :, i].numpy()
    plt.imshow(feature_map, cmap='viridis')
    plt.title(f'Filter\n{i+1}', fontsize=9)
    plt.axis('off')
    plt.colorbar(fraction=0.046, pad=0.04)

plt.suptitle('Conv2D Feature Maps - Each Filter Detects Different Patterns', 
             fontsize=13, fontweight='bold', y=1.05)
plt.tight_layout()
plt.show()

print("\nüí° Interpretation:")
print("  ‚Ä¢ Each feature map shows what a specific filter detected")
print("  ‚Ä¢ Brighter/warmer colors = stronger activation = feature detected")
print("  ‚Ä¢ Different filters detect edges, curves, corners, etc.")

# Show what happens after pooling
pool_start = time.time()
pooling_layer = model_complete.layers[4]  # MaxPooling2D
pooled_output = pooling_layer(bn1_output)
pool_time = time.time() - pool_start

print(f"\nüìâ After MaxPooling2D(2,2): {pooled_output.shape}")
print(f"  - Reduced spatial dimensions by 75%: {conv1_output.shape[1:3]} ‚Üí {pooled_output.shape[1:3]}")
print(f"  - But kept all 32 feature maps")
print(f"  ‚è±Ô∏è  MaxPooling inference: {pool_time*1000:.2f} ms")

viz_time = time.time() - viz_start
print(f"\n‚è±Ô∏è  Total visualization time: {viz_time:.3f} seconds")

# Compare original conv output vs pooled
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
fig.suptitle('Before vs After MaxPooling - Filter 0', fontsize=14, fontweight='bold')

for i in range(5):
    # Before pooling
    axes[0, i].imshow(conv1_output[0, :, :, i].numpy(), cmap='viridis')
    axes[0, i].set_title(f'Before\n{conv1_output.shape[1]}x{conv1_output.shape[2]}', fontsize=10)
    axes[0, i].axis('off')
    
    # After pooling
    axes[1, i].imshow(pooled_output[0, :, :, i].numpy(), cmap='viridis')
    axes[1, i].set_title(f'After\n{pooled_output.shape[1]}x{pooled_output.shape[2]}', fontsize=10)
    axes[1, i].axis('off')

plt.tight_layout()
plt.show()

print("\n‚úÖ MaxPooling keeps the strongest activations while reducing size!")

# ============================================================================
# 11. BEST PRACTICES SUMMARY
# ============================================================================
print("\n" + "="*80)
print("11. BEST PRACTICES & KEY TAKEAWAYS")
print("="*80)

print("\nüìã Common Architecture Patterns:")
print("\nüñºÔ∏è Image Classification:")
print("  Conv2D -> BatchNorm -> MaxPooling -> Dropout")
print("  Repeat 2-3 times, then: Flatten -> Dense -> Dropout -> Output")

print("\nüìù Text Classification:")
print("  Embedding -> LSTM/GRU -> Dropout -> Dense -> Output")

print("\nüìä Regression:")
print("  Dense -> BatchNorm -> Activation -> Dropout")
print("  Repeat, then: Dense(1, linear)")

print("\nüéØ Activation Functions:")
print("  ‚Ä¢ Hidden layers: 'relu'")
print("  ‚Ä¢ Binary output: 'sigmoid'")
print("  ‚Ä¢ Multi-class: 'softmax'")
print("  ‚Ä¢ Regression: None or 'linear'")

print("\nüõ°Ô∏è Regularization:")
print("  ‚Ä¢ Dropout: 0.2-0.5")
print("  ‚Ä¢ BatchNormalization: After layer, before activation")
print("  ‚Ä¢ Early stopping: Monitor val_loss")

print("\n‚öôÔ∏è Training Tips:")
print("  ‚Ä¢ Optimizer: Adam (good default)")
print("  ‚Ä¢ Batch size: 32, 64, 128, 256")
print("  ‚Ä¢ Learning rate: Start with 0.001")
print("  ‚Ä¢ Use validation split: 0.1-0.2")

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "="*80)
print("üéâ CONGRATULATIONS! YOU'VE COMPLETED THE KERAS LAYERS GUIDE!")
print("="*80)

print("\n‚úÖ What you learned:")
print("  1. Dense - Fully connected layers")
print("  2. Conv2D - Feature extraction from images")
print("  3. MaxPooling - Dimension reduction")
print("  4. Dropout - Prevent overfitting")
print("  5. BatchNormalization - Faster, stable training")
print("  6. LSTM/GRU - Sequential data processing")
print("  7. Embedding - Word/category vectors")
print("  8. Flatten - Conv to Dense transition")

print("\n‚è±Ô∏è  PERFORMANCE SUMMARY:")
print(f"  ‚Ä¢ Setup & imports: {setup_time:.2f}s")
print(f"  ‚Ä¢ Data loading: {load_time:.2f}s")
print(f"  ‚Ä¢ Preprocessing: {preprocess_time:.2f}s")
print(f"  ‚Ä¢ Model building: {build_time:.3f}s")
print(f"  ‚Ä¢ Model compilation: {compile_time:.3f}s")
print(f"  ‚Ä¢ Training (5 epochs): {train_time:.2f}s ({train_time/60:.2f} min)")
print(f"  ‚Ä¢ Evaluation: {eval_time:.2f}s")
print(f"  ‚Ä¢ Training speed: {samples_per_second:.0f} samples/sec")
print(f"  ‚Ä¢ Inference speed: {len(x_test)/eval_time:.0f} samples/sec")
print(f"  ‚Ä¢ Single sample: {avg_single_time:.2f}ms")
print(f"  ‚Ä¢ Test accuracy: {test_acc*100:.2f}%")

print("\nüöÄ Next Steps:")
print("  ‚Ä¢ Experiment with different architectures")
print("  ‚Ä¢ Try Fashion MNIST or CIFAR-10")
print("  ‚Ä¢ Use data augmentation")
print("  ‚Ä¢ Explore transfer learning")
print("  ‚Ä¢ Build custom layers")

print("\nüíæ Save your model:")
print("  model_complete.save('my_model.h5')")
print("  loaded = keras.models.load_model('my_model.h5')")

print("\n" + "="*80)
print("Happy Deep Learning! üß†üéØ")
print("="*80)
